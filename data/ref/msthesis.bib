@mastersthesis{vaidya_reducing_2021,
    address = {Rochester, NY-14623, USA},
    title = {Reducing Catastrophic Forgetting in Self-Organizing Maps},
    doi = {https://doi.org/10.57673/GCCIS-10994},
    url = {https://repository.rit.edu/theses/10994},
    abstract = {An agent that is capable of continual or lifelong learning is able to continuously learn from potentially infinite streams of pattern sensory data. One major historic diﬃculty in building agents capable of such learning is that neural systems struggle to retain previously-acquired knowledge when learning from new data samples. This problem is known as catastrophic forgetting and remains an unsolved problem in the domain of machine learning to this day. To overcome catastrophic forgetting, diﬀerent approaches have been proposed. One major line of thought advocates the use of memory buﬀers to store data where the stored data is then used to randomly retrain the model to improve memory retention. However, storing and giving access to previous physical data points results in a variety of practical diﬃculties particularly with respect to growing memory storage costs. In this work, we propose an alternative way to tackle the problem of catastrophic forgetting, inspired by and building on top of a classical neural model, the self-organizing map (SOM) which is a form of unsupervised clustering. Although the SOM has the potential to combat forgetting through the use of pattern-specializing units, we uncover that it too suﬀers from the same problem and this forgetting becomes worse when the SOM is trained in a task incremental fashion. To mitigate this, we propose a generalization of the SOM, the continual SOM (c-SOM), which introduces several novel mechanisms to improve its memory retention – new decay functions and generative resampling schemes to facilitate generative replay in the model. We perform extensive experiments using split-MNIST with these approaches, demonstrating that the c-SOM significantly improves over the classical SOM. Additionally, we come up with a new performance metric αmem to measure the eﬃcacy of SOMs trained in a task incremental fashion, providing a benchmark for other competitive learning models.},
    language = {English},
    school = {Rochester Institute of Technology},
    author = {Vaidya, Hitesh U.},
    month = {nov},
    year = {2021}
} 